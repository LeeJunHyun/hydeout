---
layout: post
title: '[CS294] Lecture 1 : Introduction and Course Overview'
categories:
  - Deep Learning
tags:
  - deep learning
  - reinforcement learning
  - CS294
  - course review
---

UC Berkeley의 강화학습 강의 CS294(2018 Fall semester)를 정리한 포스트입니다.

* [Course website](http://rail.eecs.berkeley.edu/deeprlcourse/)
* [Youtube video](https://www.youtube.com/playlist?list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37)
* [Reddit](https://www.reddit.com/r/berkeleydeeprlcourse/)

강의에 앞서, Assignments는 `Tensorflow` 같은 패키지를 사용하여 신경망을 학습하는 것이 나올 것입니다. [MNIST tutorial](https://leejunhyun.github.io/coding/2018/09/01/TF-fashion-mnist.html) 정도는 할 수 있어야 합니다.


코스 전체에서 다루는 주제입니다. (자세한 항목은 syllabus 참조하시기 바랍니다.)
1. From supervised learning to decision making
2. Model-free algorithms: Q-learning, policy gradients, actor-critic
3. Advanced model learning and prediction
4. Exploration
5. Transfer and multi-task learning, meta-learning
6. Open problems, research talks, invited lectures

---
---

#### (Deep) Reinforcement learning이란 무엇이며, 왜 해야하는가?
* Intelligent machine은 환경에 적응 가능해야한다.
* Deep learning 기술은 끊임없이 변하는 환경을 다룰 수 있게 해준다.

![CS294-01-01](/assets/img/Deeplearning/CS294/01/CS294-01-01.png)
> _강화학습은 환경과 행동에 대한 학습이다._

![CS294-01-02](/assets/img/Deeplearning/CS294/01/CS294-01-02.png)
기존의 컴퓨터비젼 영역에서는 feature들을 전문가가 직접 추출하여 분류기에 넣었다. 그러나 딥러닝을 사용한다면, 입력 이미지에서 레이블을 뽑아내기까지의 과정이 end-to-end 로 학습 가능하다. 즉, 이미지를 분류하기위해 어떤 feature를 뽑아야 하는지 고민할 필요가 없다.<br>
이와 마찬가지로 강화학습에서도 딥러닝을 사용한다면, 환경에서부터 행동까지의 과정을 end-to-end로 학습 가능하다.

#### 연속적 의사결정에서 end-to-end learning 이 갖는 의미는 무엇일까?
![CS294-01-03](/assets/img/Deeplearning/CS294/01/CS294-01-03.png)
호랑이를 인지(perception)하고, 도망(action)을 치는 일련의 과정이 end-to-end로 이루어 진다면 일종의 loop를 만든다. 즉, 도망을 친 후에 바뀌는 입력값(환경)이 다시 행동에 영향을 미치고, 그 행동이 다시 입력값(환경)에 영향을 미치고...<br>
이러한 프로세스는 로보틱스 분야에서 이용된다.
![CS294-01-04](/assets/img/Deeplearning/CS294/01/CS294-01-04.png)

#### 현실세계에 적용하려면 어떤 것들을 다루어야할까?
기본적으로 강화학습은 행동에 대한 보상(reward)을 극대화 하는 방향으로 학습한다. 그러나 더 다룰만한 주제들도 있다. 본 강의에서는 다음과 같이 좀더 심화된 주제들도 다룬다.
* example로부터 reward 함수를 학습한다. (inverse reinforcement learning)
* 도메인간의 지식 전이 학습을 한다. (transfer learning, meta-learning)
* 예측을 하도록 학습하고, 예측값을 행동에 사용한다.

보상(reward)은 게임 점수, 좋아요 수, 생존 등 다양한 곳에서부터 발생할 수 있다.<br> 
다른 이의 행동과의 차이가 적을수록 reward를 준다면 (차이가 클수록 처벌을 준다면), 그 행동을 똑같이 따라하는 방향으로 학습이 될 것이다. 자율주행을 예로 들면, 사고가 나지 않으면 reward를 주는 방식으로 강화학습을 할 수도 있지만, 운전자가 하는 운전방법을 똑같이 따라하게 학습하여 자율주행 자동차를 만들 수도 있는 것이다. (Imitation learning)<br>
관측된 행동에서부터 reward를 유추하게 할 수도 있다. 예를 들어, 로봇 팔이 쥐고 있는 컵의 내용물을 책상위의 다른 컵에 옮기도록 사람이 로봇 팔을 직접 몇번 움직여주면 (example), 이 관측된 행동이 큰 reward를 가질 수 있도록 학습을 한다. (Inverse reinforcement learning)

#### Deep Reinforcement Learning in the brain
* Deep Neural Network : 복잡한 감각기관 입력을 처리할 수 있다.
* Reward System : Basal ganglia가 reward system과 관련이 있다.
* Reinforcement Learning : 복잡한 행동을 선택 할 수 있다.
<br>

#### (Deep) RL은 어떤 분야에 잘 적용되고 있는가?
* 간단하고 규칙이 알려진 영역
* 감각기관 입력을 통해 간단한 기술을 학습할 수 있고, 충분한 경험이 주어진 경우
* 전문가의 행동이 충분히 주어졌을 때, 모방을 학습하는 경우

#### 해결해야할 과제는?
* 인간은 빠르게 학습하지만, Deep RL의 학습은 보통 느리다.
* 인간은 과거의 지식을 재사용할 수 있다. (Transfer Learning)
* reward function이 무엇이어야 하는지 확실치 않다.
* prediction의 역할이 무엇이어야 하는지 확실치 않다.


